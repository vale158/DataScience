{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DL_Tarea1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vale158/DataScience/blob/master/DL_Tarea1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "luuXVmoTdYt2"
      },
      "source": [
        "## Tarea 1. Aprendizaje Profundo\n",
        "\n",
        "Sonia López Rito/ 183349\n",
        "\n",
        "---\n",
        "**Objetivo:** Entrenar un modelo MLP para predecir la salida de una compuerta lógica dadas dos entradas binarias (XOR).\n",
        "\n",
        "Para simplificar  el problema usamos entradas de valores reales en lugar de entradas binarias. Cuando los valores de entrada tengan el mismo signo, la salida debe ser uno, si los valores de entrada tienen signo distinto, la salida debe ser cero."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "xM66yNP0ccMw",
        "outputId": "2ca860bd-50fd-4a3c-f148-a3026acbab41"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Entrada del perceptron multicapa  (MLP)\n",
        "X = np.array([[1,1], [1,-1], [-1,-1], [-1,1]])\n",
        "# Salida del MLP\n",
        "y = np.array([[0], [1], [0], [1]])\n",
        "\n",
        "# Gráfica del training data\n",
        "fig, ax = plt.subplots()\n",
        "for i in range(y.shape[0]):\n",
        "  if y[i][0] == 0:\n",
        "    marker = 'ro'\n",
        "  else:\n",
        "    marker = 'bo'\n",
        "  ax.plot(X[i][0], X[i][1], marker)\n",
        "ax.axhline(y=0, color='k')\n",
        "ax.axvline(x=0, color='k')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.lines.Line2D at 0x7f48c9b6de10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDsAe6j1koco"
      },
      "source": [
        "Dado que estos puntos no son separables linealmente, no podemos encontrar una línea que clasifique a los puntos correctamente, construiremos un perceptron multicapa no lineal para hacer predicciones.\n",
        "\n",
        "Definimos la función de activación, en este caso será la función sigmoide"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o24kLDLJk0ka"
      },
      "source": [
        "# Función Sigmoide\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derivada de la función Sigmoide\n",
        "def derivative_sigmoid(x):\n",
        "    return x * (1 - x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_xAIIFCnOj0"
      },
      "source": [
        "El MLP consiste de una capa oculta y una capa de salida para mapear el vector oculto a los valores de salida.\n",
        "\n",
        "Primero inicializamos los pesos y el sesgo de cada capa así como las épocas de entrenamiento y la tasa de aprendizaje."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfukE1dRnPc5"
      },
      "source": [
        "epoch = 5000 \n",
        "learning_rate = 0.1\n",
        "\n",
        "# Dimensión de cada capa\n",
        "d_in = X.shape[1] # Carácteristicas\n",
        "d_h = 3   # Capa oculta\n",
        "d_out = 1 # Capa de salida\n",
        "\n",
        "# Pesos y sesgo \n",
        "wh = np.random.uniform(size=(d_in, d_h))\n",
        "bh = np.random.uniform(size=(1, d_h))\n",
        "wout = np.random.uniform(size=(d_h, d_out))\n",
        "bout = np.random.uniform(size=(1, d_out))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cXksajVqIRS"
      },
      "source": [
        "Para cada iteración de entrenamiento nos acercamos un paso para obtener el valor predecido y calcular la pérdida entre la predicción y el valor real. Usaremos la diferencia entre dos valores para como la función de pérdida. Entonces podemos calcular los gradientes y finalmente actualizar las ponderaciones y sesgos (bias)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21Ayb0aGqJWp",
        "outputId": "65707c5f-2669-4fa7-e9dd-de03b910dca9"
      },
      "source": [
        "for i in range(epoch):\n",
        "    # Forwardpass\n",
        "    h = sigmoid(X.dot(wh) + bh)\n",
        "    y_pred = sigmoid(h.dot(wout) + bout)\n",
        "    \n",
        "    # Función de pérdida\n",
        "    loss = (y_pred - y).sum()\n",
        "    if i % 500 == 0:\n",
        "        print('Epoch', i, ':', loss)\n",
        "\n",
        "    # Backpropagation \n",
        "    grad_y_pred = (y - y_pred) * derivative_sigmoid(y_pred)\n",
        "    grad_wout = h.T.dot(grad_y_pred)\n",
        "    grad_bout = np.sum(grad_y_pred, axis=0, keepdims=True)\n",
        "    grad_h = grad_y_pred.dot(wout.T) * derivative_sigmoid(h)\n",
        "    grad_wh = X.T.dot(grad_h)\n",
        "    grad_bh = np.sum(grad_h, axis=0, keepdims=True)\n",
        "\n",
        "    # Actualización de pesos y sesgo\n",
        "    wout += grad_wout * learning_rate\n",
        "    bout += grad_bout * learning_rate\n",
        "    wh += grad_wh * learning_rate\n",
        "    bh += grad_bh * learning_rate\n",
        "    \n",
        "print('Prediction of training data:')\n",
        "print(y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0 : 1.3738782577319841\n",
            "Epoch 500 : 0.013324441264700004\n",
            "Epoch 1000 : 0.04108653139490659\n",
            "Epoch 1500 : 0.0704150838117753\n",
            "Epoch 2000 : 0.021180472255469374\n",
            "Epoch 2500 : 0.024149511532678802\n",
            "Epoch 3000 : 0.021443771621126484\n",
            "Epoch 3500 : 0.018294752093744843\n",
            "Epoch 4000 : 0.015928912650717664\n",
            "Epoch 4500 : 0.014162613223383441\n",
            "Prediction of training data:\n",
            "[[0.06871203]\n",
            " [0.93242838]\n",
            " [0.07913578]\n",
            " [0.93252943]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WNoaHSaWqbLK"
      },
      "source": [
        "Los valores predichos son cercanos a los datos de entrenamiento. Ya que son valores reales para obtener la salida binaria, podemos simplemente establecer el umbral de salida para decidir cual etiqueta podemos asignar."
      ]
    }
  ]
}